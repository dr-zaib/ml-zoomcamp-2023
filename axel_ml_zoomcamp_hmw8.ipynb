{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a61fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0008c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-21 16:38:08--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
      "Risoluzione di github.com (github.com)... 140.82.121.4\n",
      "Connessione a github.com (github.com)|140.82.121.4|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 302 Found\n",
      "Posizione: https://objects.githubusercontent.com/github-production-release-asset-2e65be/405934815/e6c56cb7-dce1-463f-865b-01e913c38485?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231121%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231121T153808Z&X-Amz-Expires=300&X-Amz-Signature=563c52efd6d2b60f35e40fff90b408e94b2edd47fa96e77cee2eb15d044939aa&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=405934815&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [segue]\n",
      "--2023-11-21 16:38:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/405934815/e6c56cb7-dce1-463f-865b-01e913c38485?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231121%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231121T153808Z&X-Amz-Expires=300&X-Amz-Signature=563c52efd6d2b60f35e40fff90b408e94b2edd47fa96e77cee2eb15d044939aa&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=405934815&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
      "Risoluzione di objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connessione a objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 200 OK\n",
      "Lunghezza: 117446836 (112M) [application/octet-stream]\n",
      "Salvataggio in: ‘data.zip.1’\n",
      "\n",
      "data.zip.1          100%[===================>] 112,01M  3,68MB/s    in 30s     \n",
      "\n",
      "2023-11-21 16:38:39 (3,68 MB/s) - ‘data.zip.1’ salvato [117446836/117446836]\n",
      "\n",
      "Archive:  data.zip\n",
      "replace data/test/bee/10007154554_026417cfd0_n.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfef4b51",
   "metadata": {},
   "source": [
    "**model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86b7916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (150, 150, 3)\n",
    "n_filters = 32\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "\n",
    "conv_layer = keras.layers.Conv2D(\n",
    "    filters=n_filters,\n",
    "    kernel_size=kernel_size,\n",
    "    activation='relu', \n",
    "    input_shape=input_shape\n",
    ")\n",
    "\n",
    "\n",
    "pool_size = (2, 2)\n",
    "max_pool = keras.layers.MaxPooling2D(\n",
    "    pool_size=pool_size\n",
    ")\n",
    "\n",
    "flat_layer = keras.layers.Flatten()\n",
    "\n",
    "dense_layer = keras.layers.Dense(64, activation='relu')\n",
    "\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "\n",
    "lr=0.002 \n",
    "momentum=0.8\n",
    "sgd_optimizer = keras.optimizers.SGD(learning_rate=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "789f1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(conv_layer)\n",
    "model.add(max_pool)\n",
    "model.add(flat_layer)\n",
    "model.add(dense_layer)\n",
    "model.add(output_layer)\n",
    "\n",
    "model.compile(optimizer=sgd_optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b67b8af",
   "metadata": {},
   "source": [
    "**question 1**\n",
    "\n",
    "==> binary crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb15f5",
   "metadata": {},
   "source": [
    "**question 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37352703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 175232)            0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1355ab",
   "metadata": {},
   "source": [
    "**generators and training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2fcccf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_ds = train_generator.flow_from_directory(\n",
    "    './data/train', \n",
    "    target_size=(input_shape[:2]), \n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_ds = test_generator.flow_from_directory(\n",
    "    './data/test', \n",
    "    target_size=(input_shape[:2]), \n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "468fe57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 14s 73ms/step - loss: 0.6889 - accuracy: 0.5442 - val_loss: 0.6646 - val_accuracy: 0.5926\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 13s 70ms/step - loss: 0.6567 - accuracy: 0.5964 - val_loss: 0.6299 - val_accuracy: 0.6307\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 13s 70ms/step - loss: 0.6170 - accuracy: 0.6475 - val_loss: 0.6121 - val_accuracy: 0.6166\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 13s 70ms/step - loss: 0.5843 - accuracy: 0.6959 - val_loss: 0.5688 - val_accuracy: 0.7124\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 13s 70ms/step - loss: 0.5418 - accuracy: 0.7327 - val_loss: 0.5367 - val_accuracy: 0.7462\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 13s 71ms/step - loss: 0.5238 - accuracy: 0.7536 - val_loss: 0.5394 - val_accuracy: 0.7429\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 13s 71ms/step - loss: 0.5008 - accuracy: 0.7710 - val_loss: 0.5297 - val_accuracy: 0.7614\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 13s 70ms/step - loss: 0.4746 - accuracy: 0.7900 - val_loss: 0.5231 - val_accuracy: 0.7353\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 13s 71ms/step - loss: 0.4464 - accuracy: 0.8023 - val_loss: 0.5409 - val_accuracy: 0.7429\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 13s 71ms/step - loss: 0.4248 - accuracy: 0.8170 - val_loss: 0.5471 - val_accuracy: 0.7266\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=test_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66682c73",
   "metadata": {},
   "source": [
    "**question 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8af29319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7431329786777496"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_accuracy = history.history['accuracy']\n",
    "\n",
    "training_accuracy_median = np.median(training_accuracy)\n",
    "training_accuracy_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1457015",
   "metadata": {},
   "source": [
    "**question 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51c63661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0845219954105831"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loss = history.history['loss']\n",
    "\n",
    "training_loss_std = np.std(training_loss)\n",
    "training_loss_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8aaf7",
   "metadata": {},
   "source": [
    "**data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14fe549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_ds = train_generator.flow_from_directory(\n",
    "    './data/train', \n",
    "    target_size=(input_shape[:2]), \n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_ds = test_generator.flow_from_directory(\n",
    "    './data/test', \n",
    "    target_size=(input_shape[:2]), \n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d625bca",
   "metadata": {},
   "source": [
    "**question 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c97991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.5143 - accuracy: 0.7550 - val_loss: 0.5122 - val_accuracy: 0.7440\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.4897 - accuracy: 0.7718 - val_loss: 0.5007 - val_accuracy: 0.7625\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.4864 - accuracy: 0.7743 - val_loss: 0.5089 - val_accuracy: 0.7614\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.4803 - accuracy: 0.7803 - val_loss: 0.4797 - val_accuracy: 0.7810\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.4731 - accuracy: 0.7822 - val_loss: 0.5038 - val_accuracy: 0.7636\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 23s 124ms/step - loss: 0.4848 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7789\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4752 - val_accuracy: 0.7843\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.4621 - accuracy: 0.7841 - val_loss: 0.4935 - val_accuracy: 0.7789\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 22s 118ms/step - loss: 0.4667 - accuracy: 0.7873 - val_loss: 0.4656 - val_accuracy: 0.7908\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.4585 - accuracy: 0.7909 - val_loss: 0.4802 - val_accuracy: 0.7745\n"
     ]
    }
   ],
   "source": [
    "add_epochs = 10\n",
    "\n",
    "add_history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=add_epochs,\n",
    "    validation_data=test_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5bc91118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.530410535633564"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_loss'].extend(add_history.history['val_loss'])\n",
    "\n",
    "mean_test_loss = np.mean(history.history['val_loss'])\n",
    "mean_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922f4a9",
   "metadata": {},
   "source": [
    "**question 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f764e1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7814814925193787"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_test_accuracy = np.mean(add_history.history['val_accuracy'][5:])\n",
    "avg_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593406cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1c931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
